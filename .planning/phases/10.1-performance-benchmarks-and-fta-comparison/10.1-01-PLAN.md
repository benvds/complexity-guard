---
phase: 10.1-performance-benchmarks-and-fta-comparison
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - benchmarks/scripts/setup.sh
  - benchmarks/scripts/bench-quick.sh
  - benchmarks/scripts/bench-full.sh
  - benchmarks/scripts/bench-stress.sh
  - benchmarks/projects/.gitkeep
  - benchmarks/results/.gitkeep
  - .gitignore
autonomous: true
requirements:
  - "BENCH-INFRA: Benchmark directory structure and project clone infrastructure"
  - "BENCH-E2E: End-to-end hyperfine benchmark scripts for quick/full/stress suites"

must_haves:
  truths:
    - "Running setup.sh clones ~10 quick-suite projects (or all 76 for full suite) from tests/public-projects.json into benchmarks/projects/"
    - "Running bench-quick.sh produces hyperfine JSON output with wall-clock and memory statistics for both CG and FTA on 10 projects"
    - "Running bench-full.sh produces hyperfine JSON output for all 76 projects"
    - "Running bench-stress.sh produces hyperfine JSON output for massive repos (vscode, TypeScript)"
    - "FTA is auto-installed into a temp directory by each benchmark script (no pre-install assumption)"
    - "CG is built with ReleaseFast optimization before benchmarking"
    - "benchmarks/projects/ is git-ignored so cloned repos are not committed"
  artifacts:
    - path: "benchmarks/scripts/setup.sh"
      provides: "Project clone infrastructure with shallow clone, caching, and tier selection"
    - path: "benchmarks/scripts/bench-quick.sh"
      provides: "Quick suite hyperfine benchmark (10 projects, CG vs FTA)"
    - path: "benchmarks/scripts/bench-full.sh"
      provides: "Full suite hyperfine benchmark (76 projects)"
    - path: "benchmarks/scripts/bench-stress.sh"
      provides: "Stress-test suite for massive repos with timeout"
  key_links:
    - from: "benchmarks/scripts/setup.sh"
      to: "tests/public-projects.json"
      via: "python3 JSON parsing for git_url and latest_stable_tag"
      pattern: "public-projects\\.json"
    - from: "benchmarks/scripts/bench-quick.sh"
      to: "benchmarks/results/"
      via: "hyperfine --export-json"
      pattern: "export-json"
---

<objective>
Create the benchmark infrastructure: directory structure, project clone scripts, and end-to-end hyperfine benchmark scripts that compare ComplexityGuard against FTA on real-world TypeScript/JavaScript projects.

Purpose: Establish the measurement foundation for Phase 10.1 — all subsequent plans (Zig subsystem benchmarks, metric accuracy comparison, documentation) depend on this infrastructure being in place and functional.

Output: benchmarks/ directory with setup script, three benchmark scripts (quick/full/stress), .gitignore updates.
</objective>

<execution_context>
@/home/ben/.claude/get-shit-done/workflows/execute-plan.md
@/home/ben/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/10.1-performance-benchmarks-and-fta-comparison/10.1-CONTEXT.md
@.planning/phases/10.1-performance-benchmarks-and-fta-comparison/10.1-RESEARCH.md
@tests/public-projects.json
@build.zig
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create benchmark directory structure, .gitignore updates, and setup.sh clone script</name>
  <files>
    benchmarks/scripts/setup.sh
    benchmarks/projects/.gitkeep
    benchmarks/results/.gitkeep
    .gitignore
  </files>
  <action>
    1. Create directory structure:
       - `benchmarks/scripts/` (shell scripts)
       - `benchmarks/projects/.gitkeep` (cloned repos, git-ignored)
       - `benchmarks/results/.gitkeep` (JSON results, committed)
       - `benchmarks/src/` (for Plan 02's Zig module)

    2. Update `.gitignore` — add these entries:
       ```
       # Benchmark cloned projects (large, ephemeral)
       benchmarks/projects/*/
       !benchmarks/projects/.gitkeep
       ```

    3. Create `benchmarks/scripts/setup.sh`:
       - Parse `tests/public-projects.json` using python3 — access `data['libraries']` to extract project entries
       - Accept `--suite` flag: `quick` (default, ~10 projects), `full` (all 76), `stress` (massive repos only)
       - Quick suite projects (hardcoded list of 10 names): zod, got, dayjs, vite, nestjs, webpack, typeorm, rxjs, effect, vscode
       - Full suite: all 76 projects from the JSON
       - Stress suite: only vscode, TypeScript (compiler), and effect (the 3 largest)
       - For each project: shallow clone with `git clone --branch <latest_stable_tag> --depth 1 --single-branch --no-tags <git_url> benchmarks/projects/<name>`
       - Skip if `benchmarks/projects/<name>` already exists (cache behavior)
       - Print progress: "Cloning: <name> @ <tag>" or "Cached: <name>"
       - Use `set -euo pipefail` for safety
       - Make executable: `chmod +x`

    4. Quick suite selection rationale (per RESEARCH.md): 2 small (zod, dayjs), 3 medium (got, vite, rxjs), 3 large (nestjs, webpack, typeorm), 2 massive (effect, vscode) — spanning all quality tiers and both TS/JS.
  </action>
  <verify>
    - `bash benchmarks/scripts/setup.sh --suite quick` successfully clones the 10 quick-suite projects into `benchmarks/projects/`
    - Running setup.sh a second time shows "Cached:" for all projects (no re-clone)
    - `.gitignore` contains the benchmarks/projects exclusion
    - `git status` does NOT show the cloned project directories as untracked
  </verify>
  <done>
    benchmarks/ directory exists with scripts/, projects/.gitkeep, results/.gitkeep. setup.sh clones projects from public-projects.json with tier selection and caching. Cloned repos are git-ignored.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create hyperfine end-to-end benchmark scripts (quick, full, stress)</name>
  <files>
    benchmarks/scripts/bench-quick.sh
    benchmarks/scripts/bench-full.sh
    benchmarks/scripts/bench-stress.sh
  </files>
  <action>
    1. All three scripts share a common pattern:
       - `set -euo pipefail`
       - Determine PROJECT_ROOT via `git rev-parse --show-toplevel`
       - Build CG in ReleaseFast mode: `cd "$PROJECT_ROOT" && zig build -Doptimize=ReleaseFast`
       - Set `CG_BIN="$PROJECT_ROOT/zig-out/bin/complexity-guard"`
       - Auto-install FTA into temp dir: `FTA_TEMP=$(mktemp -d /tmp/fta-bench-XXXX)` then `npm install fta-cli@3.0.0 --prefix "$FTA_TEMP" --quiet 2>/dev/null` then `FTA_BIN="$FTA_TEMP/node_modules/.bin/fta"`
       - Verify both binaries exist and print versions
       - Create timestamped results directory: `RESULTS_DIR="$PROJECT_ROOT/benchmarks/results/baseline-$(date +%Y-%m-%d)"`; `mkdir -p "$RESULTS_DIR"`
       - Clean up FTA temp on exit: `trap "rm -rf $FTA_TEMP" EXIT`

    2. `bench-quick.sh`:
       - Check that quick-suite projects are cloned (prompt to run setup.sh if not)
       - Quick suite list: zod got dayjs vite nestjs webpack typeorm rxjs effect vscode
       - For each project, run hyperfine comparing CG vs FTA:
         ```
         HYPERFINE=$(command -v hyperfine || echo /home/ben/.cargo/bin/hyperfine)
         "$HYPERFINE" \
           --warmup 3 \
           --runs 15 \
           --export-json "$RESULTS_DIR/${project}-quick.json" \
           "${CG_BIN} --format json --fail-on none ${PROJECT_DIR}" \
           "${FTA_BIN} --json --exclude-under 0 ${PROJECT_DIR}"
         ```
       - Use `--fail-on none` for CG to prevent exit code 1 breaking hyperfine
       - Use `--exclude-under 0` for FTA to disable minimum-lines filter (apples-to-apples)
       - Print summary table at the end showing mean time for each project for both tools

    3. `bench-full.sh`:
       - Same pattern as quick but iterates over ALL 76 projects
       - Uses `setup.sh --suite full` prerequisite check
       - Individual JSON per project: `$RESULTS_DIR/${project}-full.json`
       - Longer timeout awareness: some projects may take minutes

    4. `bench-stress.sh`:
       - Only runs against vscode, TypeScript (compiler), effect
       - Uses `--runs 5` instead of 15 (massive repos are slow)
       - Uses `--warmup 1` instead of 3 (each warmup is expensive)
       - Adds a 5-minute timeout per hyperfine invocation (use `timeout 300 hyperfine ...`)
       - Documents single-threaded limitation: CG has no parallelization yet (Phase 12)
       - Individual JSON per project: `$RESULTS_DIR/${project}-stress.json`

    5. All scripts: Make executable with `chmod +x`.
  </action>
  <verify>
    - `bash benchmarks/scripts/bench-quick.sh` completes successfully on at least the smallest project (zod or dayjs)
    - JSON result files appear in `benchmarks/results/baseline-YYYY-MM-DD/`
    - Each JSON file contains hyperfine schema with `results[].mean`, `results[].stddev`, `results[].memory_usage_byte`
    - Both CG and FTA results appear in each JSON file (two entries in `results` array)
    - FTA temp directory is cleaned up after script exits
  </verify>
  <done>
    Three benchmark scripts exist and produce hyperfine JSON results. bench-quick.sh benchmarks 10 projects, bench-full.sh benchmarks all 76, bench-stress.sh benchmarks massive repos with timeout protection. All scripts auto-install FTA, build CG in ReleaseFast, and use statistical rigor (warmup + multiple runs).
  </done>
</task>

</tasks>

<verification>
1. `ls benchmarks/scripts/` shows setup.sh, bench-quick.sh, bench-full.sh, bench-stress.sh
2. `ls benchmarks/projects/.gitkeep benchmarks/results/.gitkeep` — both exist
3. `grep "benchmarks/projects" .gitignore` — cloned projects are excluded from git
4. `bash benchmarks/scripts/setup.sh --suite quick` clones 10 projects
5. `bash benchmarks/scripts/bench-quick.sh` produces JSON results with hyperfine schema for at least one project
6. Verify FTA is auto-installed and cleaned up (no leftover /tmp/fta-bench-* directories)
</verification>

<success_criteria>
- Benchmark infrastructure is functional: directory structure, clone scripts, and hyperfine benchmark scripts all work end-to-end
- Quick suite of 10 projects can be cloned and benchmarked against both CG and FTA
- Results are in JSON format suitable for automated comparison and historical tracking
- CG is always benchmarked in ReleaseFast mode (fair comparison with FTA's compiled binary)
</success_criteria>

<output>
After completion, create `.planning/phases/10.1-performance-benchmarks-and-fta-comparison/10.1-01-SUMMARY.md`
</output>
