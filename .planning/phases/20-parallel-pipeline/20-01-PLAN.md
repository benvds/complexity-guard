---
phase: 20-parallel-pipeline
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - rust/Cargo.toml
  - rust/src/lib.rs
  - rust/src/pipeline/mod.rs
  - rust/src/pipeline/discover.rs
  - rust/src/pipeline/parallel.rs
autonomous: true
requirements:
  - PIPE-01
  - PIPE-02
  - PIPE-03

must_haves:
  truths:
    - "discover_files() recursively finds .ts/.tsx/.js/.jsx files in directories"
    - "discover_files() excludes hardcoded dirs (node_modules, .git, dist, etc.) and .d.ts files"
    - "discover_files() applies user-supplied include/exclude glob patterns via globset"
    - "analyze_files_parallel() runs analyze_file() across paths using a rayon thread pool with configurable thread count"
    - "Results from parallel analysis are sorted by path for deterministic output"
  artifacts:
    - path: "rust/src/pipeline/discover.rs"
      provides: "Recursive file discovery with glob filtering"
      min_lines: 60
    - path: "rust/src/pipeline/parallel.rs"
      provides: "Rayon-based parallel analysis with deterministic sort"
      min_lines: 30
    - path: "rust/src/pipeline/mod.rs"
      provides: "Pipeline module public API"
  key_links:
    - from: "rust/src/pipeline/discover.rs"
      to: "walkdir + globset"
      via: "WalkDir traversal with filter_entry for dir pruning, GlobSet for include/exclude"
      pattern: "WalkDir::new.*filter_entry"
    - from: "rust/src/pipeline/parallel.rs"
      to: "rust/src/metrics/mod.rs"
      via: "calls analyze_file() inside rayon par_iter"
      pattern: "par_iter.*analyze_file"
---

<objective>
Create the pipeline module with file discovery and parallel analysis functions.

Purpose: Implement the core library components for PIPE-01 (directory scanning with glob exclusion), PIPE-02 (parallel file analysis), and PIPE-03 (deterministic output ordering). These are pure library functions with tests, consumed by main.rs in Plan 02.

Output: `rust/src/pipeline/` module with `discover_files()` and `analyze_files_parallel()` functions, plus rayon/walkdir/globset dependencies in Cargo.toml.
</objective>

<execution_context>
@/Users/benvds/.claude/get-shit-done/workflows/execute-plan.md
@/Users/benvds/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/20-parallel-pipeline/20-RESEARCH.md
@rust/Cargo.toml
@rust/src/lib.rs
@rust/src/metrics/mod.rs
@rust/src/types.rs
@rust/src/cli/config.rs
@src/discovery/filter.zig
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add dependencies and create pipeline/discover.rs with recursive glob-filtered file discovery</name>
  <files>
    rust/Cargo.toml
    rust/src/lib.rs
    rust/src/pipeline/mod.rs
    rust/src/pipeline/discover.rs
  </files>
  <action>
1. Add dependencies to rust/Cargo.toml under [dependencies]:
   - `rayon = "1"`
   - `walkdir = "2"`
   - `globset = "0.4"`

2. Add `pub mod pipeline;` to rust/src/lib.rs.

3. Create rust/src/pipeline/mod.rs:
   - `pub mod discover;`
   - `pub mod parallel;`
   - Re-export: `pub use discover::discover_files;`
   - Re-export: `pub use parallel::analyze_files_parallel;`

4. Create rust/src/pipeline/discover.rs implementing `discover_files()`:

   **Constants:**
   - `EXCLUDED_DIRS: &[&str]` matching the Zig filter.zig list exactly: `["node_modules", ".git", "dist", "build", ".next", "coverage", "__pycache__", ".svn", ".hg", "vendor"]`

   **Helper functions:**
   - `is_target_extension(path: &Path) -> bool` — returns true for .ts/.tsx/.js/.jsx extensions
   - `is_declaration_file(path: &Path) -> bool` — returns true for paths ending with `.d.ts` or `.d.tsx`
   - `build_globset(patterns: &[String]) -> Result<GlobSet, anyhow::Error>` — constructs a GlobSet from pattern strings
   - `should_include(path: &Path, exclude: &GlobSet, include: &Option<GlobSet>) -> bool` — returns true if: is_target_extension AND NOT is_declaration_file AND NOT excluded AND (include is None OR include matches)

   **Main function:**
   ```rust
   pub fn discover_files(
       paths: &[PathBuf],
       include_patterns: &[String],
       exclude_patterns: &[String],
   ) -> anyhow::Result<Vec<PathBuf>>
   ```

   Logic:
   - Build exclude GlobSet from exclude_patterns
   - Build include GlobSet from include_patterns (None if empty)
   - For each path in `paths`:
     - If path is a directory: use `WalkDir::new(path).into_iter().filter_entry(|e| { ... })` to prune EXCLUDED_DIRS early (check `e.file_name().to_str()` against EXCLUDED_DIRS for directory entries). Then `.filter_map(|e| e.ok()).filter(|e| e.file_type().is_file())` and apply `should_include()` on each file path.
     - If path is a file: apply `should_include()` directly
   - Return collected `Vec<PathBuf>`

5. Add tests in discover.rs below `// TESTS` comment:
   - `test_is_target_extension` — .ts, .tsx, .js, .jsx return true; .rs, .py, .json return false
   - `test_is_declaration_file` — .d.ts, .d.tsx return true; .ts, .tsx return false
   - `test_excluded_dirs_matches_zig` — verify EXCLUDED_DIRS contains all 10 entries from Zig filter.zig
   - `test_discover_files_fixture_dir` — run discover_files against `../tests/fixtures/typescript/` and verify it finds .ts files, excludes non-target files
   - `test_discover_files_single_file` — pass a single .ts file path, verify it's returned
   - `test_discover_files_exclude_pattern` — use exclude pattern `**/*_cases.ts` and verify those files are filtered out
  </action>
  <verify>
    <automated>cd /Users/benvds/code/complexity-guard/rust && cargo test pipeline::discover --lib -- --nocapture 2>&1 | tail -20</automated>
  </verify>
  <done>discover_files() finds .ts/.tsx/.js/.jsx files recursively, prunes excluded directories, applies glob include/exclude patterns, and all unit tests pass.</done>
</task>

<task type="auto">
  <name>Task 2: Create pipeline/parallel.rs with rayon-based parallel analysis and deterministic sort</name>
  <files>rust/src/pipeline/parallel.rs</files>
  <action>
Create rust/src/pipeline/parallel.rs implementing parallel file analysis:

**Main function:**
```rust
pub fn analyze_files_parallel(
    paths: &[PathBuf],
    config: &AnalysisConfig,
    threads: u32,
) -> (Vec<FileAnalysisResult>, bool)
```

Logic:
1. Build a local rayon thread pool: `rayon::ThreadPoolBuilder::new().num_threads(threads as usize).build()` — use `.expect("failed to build rayon thread pool")` (not `build_global()` — avoids test interference per research pitfall #2).
2. Inside `pool.install(|| { ... })`:
   - `paths.par_iter().map(|p| analyze_file(p, config)).collect::<Vec<_>>()`
3. Partition results: `(Vec<Ok>, Vec<Err>)` using `into_iter().partition(Result::is_ok)`
4. Extract successful `FileAnalysisResult` values from Ok variants
5. Set `has_parse_errors = !errors.is_empty()`
6. **Sort by path** (PIPE-03): `files.sort_by(|a, b| a.path.cmp(&b.path))` — use PathBuf::cmp for cross-platform correctness
7. Return `(files, has_parse_errors)`

Import: `use rayon::prelude::*;`, `use crate::metrics::analyze_file;`, `use crate::types::{AnalysisConfig, FileAnalysisResult};`

**Tests** below `// TESTS` comment:
- `test_analyze_parallel_single_file` — analyze one fixture file with threads=1, verify result has correct path and functions
- `test_analyze_parallel_multiple_files` — analyze 3+ fixture files with threads=2, verify all results present and sorted by path
- `test_analyze_parallel_deterministic_order` — run twice with threads=4, verify result ordering is identical both times
- `test_analyze_parallel_invalid_file_returns_error` — include a `.rs` file in paths, verify `has_parse_errors` is true and the valid files still produce results
  </action>
  <verify>
    <automated>cd /Users/benvds/code/complexity-guard/rust && cargo test pipeline::parallel --lib -- --nocapture 2>&1 | tail -20</automated>
  </verify>
  <done>analyze_files_parallel() runs analysis on multiple files using rayon thread pool, returns results sorted by path, handles parse errors gracefully, and all unit tests pass.</done>
</task>

</tasks>

<verification>
```bash
cd /Users/benvds/code/complexity-guard/rust && cargo test pipeline --lib -- --nocapture
cd /Users/benvds/code/complexity-guard/rust && cargo build --release 2>&1 | tail -5
```

All pipeline module tests pass. Release build compiles cleanly with new dependencies.
</verification>

<success_criteria>
- `cargo test pipeline` passes all tests (discovery + parallel)
- `discover_files()` finds correct files in fixture directories
- `analyze_files_parallel()` produces sorted, deterministic results
- Parse errors in individual files do not crash the pipeline
- New dependencies (rayon, walkdir, globset) compile successfully
</success_criteria>

<output>
After completion, create `.planning/phases/20-parallel-pipeline/20-01-SUMMARY.md`
</output>
