---
phase: 12-parallelization-distribution
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/pipeline/parallel.zig
  - src/main.zig
  - src/lib.zig
  - src/output/json_output.zig
  - src/output/console.zig
autonomous: true
requirements:
  - PERF-01
  - PERF-02

must_haves:
  truths:
    - "Tool processes files in parallel using std.Thread.Pool when --threads is not 1"
    - "Tool bypasses thread pool entirely when --threads 1 (zero pool overhead)"
    - "Tool auto-detects CPU count when --threads is not specified"
    - "Output order is deterministic regardless of thread count (sorted by file path)"
    - "JSON output includes elapsed_ms and thread_count in metadata section"
    - "Verbose mode shows timing information (e.g. Analyzed N files in Xms)"
    - "All existing tests continue to pass"
  artifacts:
    - path: "src/pipeline/parallel.zig"
      provides: "Thread pool dispatch, per-file work items, result collection with mutex-protected append"
      min_lines: 80
    - path: "src/main.zig"
      provides: "Wiring of thread count from cfg, conditional parallel vs sequential path, timing capture"
    - path: "src/output/json_output.zig"
      provides: "elapsed_ms and thread_count fields in JSON output metadata"
  key_links:
    - from: "src/main.zig"
      to: "src/pipeline/parallel.zig"
      via: "analyzeFilesParallel call when thread_count > 1"
      pattern: "parallel\\.analyzeFiles"
    - from: "src/pipeline/parallel.zig"
      to: "src/parser/parse.zig"
      via: "parseFile called per-thread with thread-local parser"
      pattern: "parse\\.parseFile"
    - from: "src/main.zig"
      to: "src/output/json_output.zig"
      via: "elapsed_ms and thread_count passed to buildJsonOutput"
      pattern: "elapsed_ms|thread_count"
---

<objective>
Implement parallel file analysis using std.Thread.Pool so the tool processes files concurrently, achieving sub-2-second analysis of 10,000+ file codebases.

Purpose: The tool currently processes files sequentially. With parsing consuming 40-64% of pipeline time, parallelizing per-file analysis across CPU cores provides near-linear speedup. This is the core performance improvement for Phase 12.

Output: A new `src/pipeline/parallel.zig` module, updated `main.zig` with parallel/sequential branching, and JSON output with timing metadata.
</objective>

<execution_context>
@/home/ben/.claude/get-shit-done/workflows/execute-plan.md
@/home/ben/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/12-parallelization-distribution/12-CONTEXT.md
@.planning/phases/12-parallelization-distribution/12-RESEARCH.md
@src/main.zig
@src/parser/parse.zig
@src/lib.zig
@src/output/json_output.zig
@src/metrics/cyclomatic.zig
@src/metrics/cognitive.zig
@src/metrics/halstead.zig
@src/metrics/structural.zig
@src/metrics/scoring.zig
@src/output/console.zig
@src/output/exit_codes.zig
@src/cli/config.zig
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create parallel analysis module and wire into main.zig pipeline</name>
  <files>
    src/pipeline/parallel.zig
    src/main.zig
    src/lib.zig
  </files>
  <action>
Create `src/pipeline/parallel.zig` with a `analyzeFilesParallel` function that:

1. **WorkerContext struct:** Holds mutex, shared results list (ArrayList of FileAnalysisResult), shared errors list, main allocator, and all metric configs (cyclomatic, cognitive, halstead, structural, scoring weights, metric thresholds, parsed_metrics).

2. **FileAnalysisResult struct:** Contains all per-file output needed by downstream code: path, threshold results slice ([]cyclomatic.ThresholdResult), structural file result (?structural.FileStructuralResult), file health score (f64), function count (u32), warning count (u32), error count (u32).

3. **analyzeFilesParallel function:**
   - Takes: allocator, file_paths ([]const []const u8), thread_count (usize), plus all metric configs, scoring weights, metric thresholds, parsed_metrics
   - Creates std.Thread.Pool with `.n_jobs = thread_count` (NOT null — the caller already resolved the count)
   - Uses std.Thread.WaitGroup for barrier
   - Spawns one work item per file via `pool.spawnWg(&wg, analyzeFileWorker, .{ ctx, path })`
   - After `wg.wait()`, sorts results by path using `std.mem.sort` with `std.mem.lessThan(u8, a.path, b.path)` comparator
   - Returns owned slice of FileAnalysisResult and a parse summary (total, successful, failed, with_errors counts)

4. **analyzeFileWorker function (called by pool):**
   - Creates per-worker ArenaAllocator from std.heap.page_allocator; `defer arena.deinit()`
   - Creates its own `tree_sitter.Parser.init()` per thread; `defer parser.deinit()` — TSParser is NOT thread-safe
   - Reads file, selects language, parses with per-thread parser
   - Runs all metric analyses: cyclomatic, cognitive, halstead, structural, scoring (same logic as current main.zig for-loop body)
   - Copies results (path via `allocator.dupe`, threshold results via `allocator.dupe`, structural result) to main allocator
   - Locks mutex ONLY for the append to shared results list — all computation happens outside the lock
   - On parse failure: locks mutex, appends to errors list, unlocks, returns

5. **Update main.zig:**
   - Import `parallel` module
   - After file discovery, resolve effective thread count:
     ```
     const cpu_count = std.Thread.getCpuCount() catch 1;
     const effective_threads: usize = if (cfg.analysis) |a| if (a.threads) |t| @intCast(t) else cpu_count else cpu_count;
     ```
   - Capture `start_time = std.time.nanoTimestamp()` before analysis
   - If `effective_threads == 1`: keep existing sequential path (existing parseFiles + for-loop)
   - If `effective_threads > 1`: call `parallel.analyzeFilesParallel(...)` which returns FileAnalysisResult slice — then convert to the same `file_results_list`, `file_scores_list`, `file_function_counts`, `total_warnings`, `total_errors`, `total_functions` that the rest of main.zig expects
   - Compute `elapsed_ms` after analysis completes (both paths)
   - If `cli_args.verbose`: print `"Analyzed {d} files in {d}ms ({d} threads)\n"` to stderr (not stdout, to avoid polluting machine-readable output)
   - Pass `elapsed_ms` and `effective_threads` to JSON output builder

6. **Update lib.zig:** Add `pub const parallel = @import("pipeline/parallel.zig");` for benchmark module access.

7. **Add test import in main.zig test block:** `_ = @import("pipeline/parallel.zig");`

**Critical implementation notes:**
- Tree-sitter TSParser is NOT thread-safe — each worker MUST create its own parser
- Worker arenas free at function exit — result data (paths, slices) must be duped to main allocator before append
- Lock mutex ONLY for the append — never hold during compute
- The `parseFile` function in parse.zig already creates a parser internally, but for the parallel path we need to avoid the overhead of creating/destroying a parser per file. Instead, the worker should create the parser once and reuse it for its batch of files. However, since `pool.spawnWg` dispatches one call per file (not batched), each worker invocation creates its own parser. This is acceptable — parser init/deinit is fast (~microseconds) and the pool reuses threads (so the same thread handles many files sequentially within the pool).
- Use `@as(usize, @intCast(t))` for u32->usize conversion of thread count
  </action>
  <verify>
Run `zig build test` — all existing tests pass. Run `zig build` — binary compiles. Run `zig build run -- --threads 1 tests/fixtures/` — sequential mode works. Run `zig build run -- tests/fixtures/` — parallel mode works (auto-detect threads). Run `zig build run -- --verbose tests/fixtures/` — timing line appears on stderr.
  </verify>
  <done>
Tool analyzes files in parallel via thread pool when threads > 1, bypasses pool when threads == 1, output is deterministic (sorted by path), verbose mode shows timing, and all existing tests pass with no memory leaks.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add elapsed_ms and thread_count to JSON output metadata</name>
  <files>
    src/output/json_output.zig
    src/main.zig
  </files>
  <action>
Update the JSON output to include timing and thread metadata per the locked decision.

1. **Update JsonOutput struct in json_output.zig:**
   - Add `metadata: Metadata` field to JsonOutput (after `files`)
   - Add `pub const Metadata = struct { elapsed_ms: u64, thread_count: u32, }` inside JsonOutput

2. **Update buildJsonOutput signature:**
   - Add `elapsed_ms: u64` and `thread_count: u32` parameters
   - Populate `metadata` field in the returned JsonOutput

3. **Update all existing tests in json_output.zig:**
   - Pass `elapsed_ms = 0` and `thread_count = 1` to all existing `buildJsonOutput` calls (backward compatible)
   - Add one new test: `test "JSON includes metadata with elapsed_ms and thread_count"` — verify metadata section exists in serialized JSON with correct values

4. **Update main.zig JSON output call:**
   - Pass `elapsed_ms` (computed after analysis) and `@intCast(effective_threads)` to `buildJsonOutput`

5. **Verify the JSON structure stays backward-compatible:**
   - version, timestamp, summary, files all remain at top level
   - metadata is a new top-level field alongside them (additive, not breaking)

**JSON output example:**
```json
{
  "version": "1.0.0",
  "timestamp": 1234567890,
  "summary": { ... },
  "files": [ ... ],
  "metadata": {
    "elapsed_ms": 450,
    "thread_count": 8
  }
}
```
  </action>
  <verify>
Run `zig build test` — all tests pass including new metadata test. Run `zig build run -- --format json tests/fixtures/` and verify JSON output contains `"metadata"` section with `"elapsed_ms"` and `"thread_count"` fields.
  </verify>
  <done>
JSON output includes metadata section with elapsed_ms (wall-clock analysis time) and thread_count (effective thread count used), all existing JSON tests pass with updated signature, new test validates metadata presence.
  </done>
</task>

</tasks>

<verification>
1. `zig build test` — all tests pass (existing + new)
2. `zig build run -- tests/fixtures/` — produces correct output with parallel analysis
3. `zig build run -- --threads 1 tests/fixtures/` — sequential mode, same output
4. `zig build run -- --verbose tests/fixtures/` 2>&1 — timing line visible on stderr
5. `zig build run -- --format json tests/fixtures/` — JSON has metadata.elapsed_ms and metadata.thread_count
6. Output from `--threads 1` and `--threads N` is identical (deterministic)
7. No memory leaks detected by test allocator
</verification>

<success_criteria>
- Parallel analysis works with configurable thread count
- Sequential bypass works with --threads 1
- Output is deterministic regardless of thread scheduling
- JSON includes elapsed_ms and thread_count metadata
- Verbose mode shows timing on stderr
- All existing tests pass
- No memory leaks
</success_criteria>

<output>
After completion, create `.planning/phases/12-parallelization-distribution/12-01-SUMMARY.md`
</output>
