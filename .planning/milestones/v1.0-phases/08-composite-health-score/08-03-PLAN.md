---
phase: 08-composite-health-score
plan: 03
type: execute
wave: 3
depends_on: ["08-02"]
requirements: [COMP-01, COMP-03]
files_modified:
  - src/cli/args.zig
  - src/cli/help.zig
  - src/cli/init.zig
  - src/main.zig
autonomous: true

must_haves:
  truths:
    - "--save-baseline flag saves current project score to config file"
    - "--save-baseline creates config file if none exists"
    - "Saved baseline is rounded to 1 decimal place"
    - "--init produces config with weights, baseline, and shows default vs suggested score"
    - "--init weight optimization maximizes starting score for the analyzed codebase"
    - "--fail-health-below N works as CLI override of config baseline"
  artifacts:
    - path: "src/cli/args.zig"
      provides: "--save-baseline flag parsed"
      contains: "save_baseline"
    - path: "src/cli/help.zig"
      provides: "Help text includes --save-baseline"
      contains: "save-baseline"
    - path: "src/cli/init.zig"
      provides: "Enhanced --init with analysis, optimization, baseline capture"
      contains: "optimizeWeights"
    - path: "src/main.zig"
      provides: "--save-baseline handler that writes score to config"
      contains: "save_baseline"
  key_links:
    - from: "src/main.zig"
      to: "src/cli/init.zig"
      via: "runInit receives analysis context for enhanced workflow"
      pattern: "init\\.runInit"
    - from: "src/main.zig"
      to: "config file on disk"
      via: "--save-baseline writes baseline to .complexityguard.json"
      pattern: "save_baseline"
---

<objective>
Implement --save-baseline flag, enhanced --init workflow with weight optimization, and --fail-health-below CLI override.

Purpose: These features complete the baseline ratchet workflow described in CONTEXT.md. Teams can capture their starting score, enforce it in CI, and use optimized weights for a favorable starting position.

Output: --save-baseline saves score to config, --init analyzes and optimizes, --fail-health-below overrides config baseline from CLI.
</objective>

<execution_context>
@/Users/benvds/.claude/get-shit-done/workflows/execute-plan.md
@/Users/benvds/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/08-composite-health-score/08-CONTEXT.md
@.planning/phases/08-composite-health-score/08-RESEARCH.md
@.planning/phases/08-composite-health-score/08-01-SUMMARY.md
@.planning/phases/08-composite-health-score/08-02-SUMMARY.md
@src/cli/args.zig (CliArgs struct, parseArgs — has fail_health_below and baseline, no save_baseline)
@src/cli/help.zig (printHelp with --baseline flag documented)
@src/cli/init.zig (runInit, generateJsonConfig)
@src/main.zig (full pipeline with scoring wired from Plan 02)
@src/metrics/scoring.zig (from Plan 01 — scoring functions)
@src/cli/config.zig (Config with baseline field from Plan 02)
</context>

<tasks>

<task type="auto">
  <name>Task 1: --save-baseline flag + CLI baseline override</name>
  <files>src/cli/args.zig, src/cli/help.zig, src/main.zig</files>
  <action>
    **args.zig changes:**
    1. Add `save_baseline: bool = false` field to CliArgs struct.
    2. In parseArgs, handle `"save-baseline"` flag: set `cli_args.save_baseline = true` (boolean flag, no value argument).

    **help.zig changes:**
    1. Add `--save-baseline` to help text in the appropriate section (near `--baseline`):
       `\\      --save-baseline         Save current health score as baseline in config`
    2. Update `--baseline` description to clarify it compares project health score:
       `\\      --baseline <SCORE>      Fail if health score drops below SCORE`
    3. Also add `--fail-health-below <SCORE>` if not already in help (it's parsed in args.zig but may not be in help). Actually, looking at existing help text, `--baseline <FILE>` is there but described as "Compare against baseline report" — this needs updating to reflect the score-based baseline. Change to:
       `\\      --fail-health-below <N> Fail if health score drops below N`
       Remove old `--baseline <FILE>` line since `--baseline` in args.zig is `?[]const u8` and was for a different purpose. Actually, keep `--baseline` as-is but reinterpret — it's a numeric score threshold. The research says to implement `--fail-health-below` as CLI analog to config baseline.

    **main.zig changes for --save-baseline:**
    1. After computing `project_score` (from Plan 02), check `cli_args.save_baseline`.
    2. If true:
       a. Determine config file path: use the discovered `config_path` if it exists, otherwise default to `.complexityguard.json`.
       b. Round score to 1 decimal: `@round(project_score * 10.0) / 10.0`.
       c. Read existing config file content (if exists). Parse as `std.json.Value` (dynamic JSON). Set `baseline` key to the rounded score float. Serialize back to file with indent_2 whitespace.
       d. If no config file exists: create a new default config (similar to --init but simpler), add baseline field, write to `.complexityguard.json`.
       e. Print to stdout: `"Baseline saved: {d:.1}\n"`.
       f. Return after saving (don't continue to normal output — save-baseline is a command, not a modifier).
    3. Important: --save-baseline must run the full analysis pipeline first (file discovery, parsing, all metrics, scoring) before saving. This means it runs AFTER scoring but BEFORE output formatting.

    **main.zig changes for --fail-health-below:**
    1. The `cli_args.fail_health_below` field already exists as `?[]const u8`.
    2. After computing `project_score`, parse this value to f64 using `std.fmt.parseFloat(f64, value)`.
    3. If parsed successfully and project_score < parsed_value - 0.5: set baseline_failed = true.
    4. This check should be combined with the config baseline check from Plan 02: either config baseline OR cli --fail-health-below can trigger baseline_failed. CLI value overrides config value if both present.

    **Testing:** Add test for --save-baseline flag parsing in args.zig. The actual save behavior is integration-level (file I/O), which is tested by running the binary.
  </action>
  <verify>`zig build test` passes. `zig build run -- --save-baseline tests/fixtures/` creates/updates `.complexityguard.json` with baseline value and prints confirmation. `zig build run -- --fail-health-below 99 tests/fixtures/` exits with code 1 (score will be below 99).</verify>
  <done>--save-baseline flag parsed and handled, writes baseline to config file. --fail-health-below works as CLI baseline override. Help text updated for all baseline-related flags.</done>
</task>

<task type="auto">
  <name>Task 2: Enhanced --init with analysis and weight optimization</name>
  <files>src/cli/init.zig, src/main.zig</files>
  <action>
    **Architecture decision (Claude's discretion):** The enhanced --init needs access to the analysis pipeline. Rather than extracting the entire pipeline into a callable function (complex refactor), have --init in main.zig run the analysis pipeline inline when the --init flag is set, then call an enhanced init function with the results.

    **main.zig changes:**
    1. Move the `--init` handling from its current position (before analysis) to AFTER the full analysis pipeline. This way --init has access to file results and scores.
    2. When `cli_args.init` is true:
       a. Run the full analysis pipeline (file discovery, parsing, metrics) — same as normal operation.
       b. Compute the project score with DEFAULT weights.
       c. Call `init.runEnhancedInit(allocator, file_results, default_score, cfg, thresholds)` — a new function that handles optimization and config writing.
       d. Return after init completes (don't produce normal output).
    3. However, --init ALSO needs to work when there are no analysis paths (user runs `complexity-guard --init` in an empty directory or before any source exists). In that case, fall back to the original simple behavior (generate default config without analysis). Check: if `analysis_paths` produces 0 files, use simple init.

    **init.zig changes:**
    1. Add `runEnhancedInit` function that receives:
       - allocator
       - file_results (the analyzed file data)
       - project_score with default weights (the "before" score)
       - the MetricThresholds (for re-scoring with trial weights)
    2. Implement weight optimization using coordinate descent (per research):
       a. Start with effective default weights (excluding duplication).
       b. For each of 4 weight dimensions (cyclomatic, cognitive, halstead, structural):
          - Try current - 0.10, current, current + 0.10 (clamped to [0.0, 1.0]).
          - Normalize all weights to sum to 1.0 after each trial.
          - Re-score all functions and compute project score with trial weights.
          - Keep the trial that maximizes project score.
       c. Repeat up to 20 iterations or until no improvement.
       d. The re-scoring uses `scoring.computeFunctionScore` with trial weights on the existing ThresholdResult data (no re-analysis needed, just re-weighting).
    3. Display output showing:
       ```
       ComplexityGuard Configuration Setup

       Analyzing codebase...
       Analyzed N files, N functions

       Default weights score: 73
       Suggested weights score: 81

       Suggested weights:
         cyclomatic: 0.15
         cognitive:  0.20
         halstead:   0.30
         structural: 0.35

       Created .complexityguard.json
       (Suggested weights and baseline saved. Remove custom weights to use ideal defaults once code improves.)
       ```
    4. Write config file using `generateJsonConfig` (update this function to accept optional weights and baseline parameter). Include the optimized weights and the optimized score as baseline.
    5. Keep original `runInit` for the no-analysis fallback case (or refactor to share code).

    **Scoring re-computation helper:** Add a helper in init.zig (or scoring.zig) that takes all ThresholdResult data and trial EffectiveWeights + MetricThresholds, and returns a project score. This avoids needing to pass the entire file_results structure — just collect all ThresholdResult slices and their function health_scores.

    Actually, simpler approach: the optimization function receives `all_threshold_results: []const []const cyclomatic.ThresholdResult` (one slice per file) and `thresholds: MetricThresholds`. For each trial weight set, it loops over all functions, computes score with trial weights, aggregates to project score. This is O(20 * 4 * total_functions) which is fast enough.

    **generateJsonConfig update:**
    1. Add optional parameters for custom weights and baseline.
    2. When weights provided, write those instead of defaults.
    3. When baseline provided, add `"baseline": N.N` field to the JSON output.
  </action>
  <verify>`zig build test` passes. `zig build run -- --init` in a directory with TS/JS files shows analysis output with default vs suggested scores and creates config with optimized weights + baseline. `zig build run -- --init` in an empty directory creates default config (fallback behavior).</verify>
  <done>--init analyzes codebase, finds optimal weights via coordinate descent, shows before/after scores, writes config with suggested weights and baseline. Fallback to simple config generation when no source files found.</done>
</task>

</tasks>

<verification>
1. `zig build test` — all tests pass
2. `zig build run -- --save-baseline tests/fixtures/` — creates/updates config with baseline, prints confirmation
3. `zig build run -- --init` (in project root with TS fixtures) — shows analysis, optimized weights, writes config
4. `zig build run -- --fail-health-below 99 tests/fixtures/` — exits 1 (score below 99)
5. `zig build run -- --fail-health-below 0 tests/fixtures/` — exits 0 (score above 0)
6. `zig build run -- --help` — shows --save-baseline and --fail-health-below in help
</verification>

<success_criteria>
- --save-baseline saves rounded score to config file
- --save-baseline creates config if none exists
- --init shows default vs suggested scores, writes optimized config + baseline
- --fail-health-below N overrides config baseline from CLI
- Weight optimization finds weights that maximize starting score
- All existing tests pass with no regressions
</success_criteria>

<output>
After completion, create `.planning/phases/08-composite-health-score/08-03-SUMMARY.md`
</output>
