---
phase: 06-cognitive-complexity
plan: 02
type: execute
wave: 2
depends_on: ["06-01"]
files_modified:
  - src/main.zig
  - src/output/console.zig
  - src/output/json_output.zig
  - src/output/exit_codes.zig
autonomous: true
requirements:
  - COGN-09

must_haves:
  truths:
    - "Tool shows both cyclomatic and cognitive complexity on the same line per function in console output"
    - "Tool shows separate hotspot lists for cyclomatic and cognitive complexity"
    - "Tool populates cognitive field in JSON output (no longer null)"
    - "Tool applies configurable cognitive thresholds (default warning=15, error=25)"
    - "Function status is worst of cyclomatic and cognitive (either metric error = function error)"
    - "Cognitive violations contribute to exit codes (error-level cognitive = non-zero exit)"
  artifacts:
    - path: "src/main.zig"
      provides: "Pipeline running both cyclomatic and cognitive analysis, merged into ThresholdResult"
      contains: "cognitive"
    - path: "src/output/console.zig"
      provides: "Side-by-side metric display with separate cognitive hotspot list"
      contains: "cognitive"
    - path: "src/output/json_output.zig"
      provides: "JSON output with populated cognitive field"
      contains: "cognitive_complexity"
    - path: "src/output/exit_codes.zig"
      provides: "Violation counting that considers both metrics"
      contains: "cognitive"
  key_links:
    - from: "src/main.zig"
      to: "src/metrics/cognitive.zig"
      via: "import and call analyzeFunctions"
      pattern: "cognitive\\.analyzeFunctions"
    - from: "src/output/console.zig"
      to: "src/metrics/cyclomatic.zig"
      via: "ThresholdResult with cognitive fields"
      pattern: "cognitive_complexity"
    - from: "src/output/json_output.zig"
      to: "src/metrics/cyclomatic.zig"
      via: "ThresholdResult cognitive_complexity field"
      pattern: "cognitive_complexity"
---

<objective>
Integrate cognitive complexity into the full analysis pipeline: main.zig runs both metrics, console shows side-by-side output with separate hotspot lists, JSON populates the cognitive field, and exit codes reflect cognitive violations.

Purpose: Makes cognitive complexity a first-class metric in ComplexityGuard's output, visible to users in both console and JSON formats.
Output: Updated main.zig pipeline, console.zig side-by-side display, json_output.zig cognitive field, exit_codes.zig combined violations.
</objective>

<execution_context>
@/Users/benvds/.claude/get-shit-done/workflows/execute-plan.md
@/Users/benvds/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-cognitive-complexity/06-CONTEXT.md
@.planning/phases/06-cognitive-complexity/06-RESEARCH.md
@.planning/phases/06-cognitive-complexity/06-01-SUMMARY.md
@src/main.zig
@src/output/console.zig
@src/output/json_output.zig
@src/output/exit_codes.zig
@src/metrics/cyclomatic.zig
@src/metrics/cognitive.zig
@src/cli/config.zig
</context>

<tasks>

<task type="auto">
  <name>Task 1: Pipeline integration — main.zig and exit_codes.zig</name>
  <files>src/main.zig, src/output/exit_codes.zig</files>
  <action>
**main.zig changes:**

1. Add import: `const cognitive = @import("metrics/cognitive.zig");`

2. In the analysis loop (where `cyclomatic.analyzeFile` is called for each parse_result), also run cognitive analysis:
   - Create cognitive config from the loaded Config. Read cognitive thresholds from `cfg.analysis.?.thresholds.?.cognitive` — if set, use those values; otherwise use CognitiveConfig.default() (warning=15, error=25).
   - For each parse_result, call `cognitive.analyzeFunctions()` on the same AST root to get cognitive results.
   - The cyclomatic `analyzeFile` returns ThresholdResult[] — after getting those, iterate through them paired with cognitive results (same function order since both walk the same tree in the same order) and set `cognitive_complexity` and `cognitive_status` fields.
   - Use `cyclomatic.validateThreshold(cog_result.complexity, cog_config.warning_threshold, cog_config.error_threshold)` to compute cognitive_status.

3. Update violation counting: After merging cognitive data into ThresholdResult, the `countViolations` function needs to count cognitive violations too.

4. Track cognitive-specific warning/error counts separately if needed for the summary, OR combine them so that a function with either cyclomatic OR cognitive violations counts.

**exit_codes.zig changes:**

Update `countViolations` to also consider cognitive_status:
```zig
pub fn countViolations(
    threshold_results: []const cyclomatic.ThresholdResult,
) struct { warnings: u32, errors: u32 } {
    var warnings: u32 = 0;
    var errors: u32 = 0;

    for (threshold_results) |result| {
        // Take the worst status from either metric
        const worst = worstStatus(result.status, result.cognitive_status);
        switch (worst) {
            .warning => warnings += 1,
            .@"error" => errors += 1,
            .ok => {},
        }
    }

    return .{ .warnings = warnings, .errors = errors };
}

fn worstStatus(a: cyclomatic.ThresholdStatus, b: cyclomatic.ThresholdStatus) cyclomatic.ThresholdStatus {
    // error > warning > ok
    if (a == .@"error" or b == .@"error") return .@"error";
    if (a == .warning or b == .warning) return .warning;
    return .ok;
}
```

This means a function with cyclomatic=ok but cognitive=error will count as an error for exit code purposes. Per user decision: same severity indicators as cyclomatic.

Update exit_codes.zig tests to cover the combined status logic:
- Test: cyclomatic ok + cognitive warning = warning
- Test: cyclomatic warning + cognitive error = error
- Test: both ok = ok

Update existing test ThresholdResult literals to include `cognitive_complexity` and `cognitive_status` fields.
  </action>
  <verify>
    Run `zig build test` — all tests pass. Run `zig build run -- tests/fixtures/typescript/cognitive_cases.ts` — verify cognitive scores appear in output.
  </verify>
  <done>main.zig runs both cyclomatic and cognitive analysis, merges results into ThresholdResult. Exit codes reflect combined worst-of status.</done>
</task>

<task type="auto">
  <name>Task 2: Console and JSON output integration</name>
  <files>src/output/console.zig, src/output/json_output.zig</files>
  <action>
**console.zig changes:**

1. Update `formatFileResults` to show both metrics on the same line per function. The current format is:
   ```
   12:0  ⚠  warning  Function 'foo' has complexity 12 (threshold: 10)  cyclomatic
   ```

   New format (per user decision — side-by-side display):
   ```
   12:0  ⚠  warning  Function 'foo' cyclomatic 12 cognitive 8
   ```

   The status indicator (symbol and severity word) should reflect the WORST of the two statuses. If cyclomatic is ok but cognitive is warning, show the warning symbol.

   Implementation: Compute worst status from `result.status` and `result.cognitive_status`. Use that for the symbol, color, and severity label. Show both values on the line.

   For verbose mode showing ok functions, show both values even when both are ok:
   ```
   12:0  ✓  ok  Function 'foo' cyclomatic 3 cognitive 2
   ```

2. Update `formatSummary` to show TWO hotspot lists:
   - "Top cyclomatic hotspots:" (existing, rename from "Top complexity hotspots:")
   - "Top cognitive hotspots:" (new, same top-5 format but sorted by cognitive_complexity)

   Build a second hotspot list sorted by `cognitive_complexity` descending, showing top 5. Only include functions with cognitive_complexity > 0.

3. Update existing console.zig tests to include `cognitive_complexity` and `cognitive_status` in ThresholdResult literals. Add new tests:
   - Test: side-by-side format shows both values
   - Test: worst status is displayed when metrics differ
   - Test: cognitive hotspot list appears in summary

**json_output.zig changes:**

1. Update `buildJsonOutput` to populate the `cognitive` field from `result.cognitive_complexity` instead of hardcoded `null`:
   ```zig
   .cognitive = result.cognitive_complexity,
   ```

   Wait — the FunctionOutput.cognitive field is `?u32`. The ThresholdResult.cognitive_complexity is `u32`. So set: `.cognitive = result.cognitive_complexity` (Zig will auto-wrap u32 into ?u32).

   Actually check: if cognitive_complexity is 0 and cognitive analysis was run, it should still be 0 (not null). Set `.cognitive = result.cognitive_complexity`.

2. Update `status` field in FunctionOutput: currently derived from `result.status` (cyclomatic only). Change to use the worst of cyclomatic and cognitive:
   ```zig
   const worst = worstStatus(result.status, result.cognitive_status);
   const func_status = switch (worst) { ... };
   ```
   Import or inline the worstStatus helper.

3. Update existing json_output.zig tests to include `cognitive_complexity` and `cognitive_status` in ThresholdResult literals. Add new test:
   - Test: cognitive field is populated (not null) when cognitive analysis has run
   - Test: status reflects worst of both metrics
  </action>
  <verify>
    Run `zig build test` — all tests pass. Run `zig build run -- tests/fixtures/typescript/cognitive_cases.ts` — verify console output shows both metrics side-by-side and cognitive hotspot list. Run `zig build run -- --format json tests/fixtures/typescript/cognitive_cases.ts` — verify JSON output has non-null cognitive values.
  </verify>
  <done>Console shows both metrics per function, separate hotspot lists. JSON populates cognitive field. Status reflects worst of both metrics.</done>
</task>

</tasks>

<verification>
1. `zig build test` passes with zero failures
2. Console output shows both cyclomatic and cognitive per function on same line
3. Console summary shows separate "Top cyclomatic hotspots" and "Top cognitive hotspots" lists
4. JSON output has non-null cognitive values for all functions
5. Exit code is non-zero when cognitive threshold is exceeded
6. `zig build run -- tests/fixtures/typescript/` produces correct output
</verification>

<success_criteria>
- Both metrics visible in every output format (console and JSON)
- Cognitive violations affect exit codes
- Separate hotspot lists for each metric
- Config file cognitive thresholds are respected
- All tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/06-cognitive-complexity/06-02-SUMMARY.md`
</output>
